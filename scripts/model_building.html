

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Building the models &mdash; protopipe 0.4.0.post2.dev128+g9149e12 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Models diagnostics" href="model_diagnostics.html" />
    <link rel="prev" title="Data training" href="data_training.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> protopipe
          

          
          </a>

          
            
            
              <div class="version">
                0.4.0.post2.dev128+g9149e12
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../usage/index.html">Workflow and usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contribute/index.html">How to contribute</a></li>
<li class="toctree-l1"><a class="reference internal" href="../AUTHORS.html">Authors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../CHANGELOG.html">Changelog</a></li>
</ul>
<p class="caption"><span class="caption-text">Structure</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../pipeline/index.html">pipeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mva/index.html">mva</a></li>
<li class="toctree-l1"><a class="reference internal" href="../perf/index.html">perf</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">scripts</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="index.html#introduction">Introduction</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html#details">Details</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="data_training.html">Data training</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Building the models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#energy-regressor">Energy regressor</a></li>
<li class="toctree-l4"><a class="reference internal" href="#g-h-classifier">g/h classifier</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="model_diagnostics.html">Models diagnostics</a></li>
<li class="toctree-l3"><a class="reference internal" href="DL2.html">Production of DL2 data</a></li>
<li class="toctree-l3"><a class="reference internal" href="optimization_cuts_IRFs.html">Optimized cuts and IRFs</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">protopipe</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">scripts</a> &raquo;</li>
        
      <li>Building the models</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/scripts/model_building.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="building-the-models">
<span id="model-building"></span><h1>Building the models<a class="headerlink" href="#building-the-models" title="Permalink to this headline">¶</a></h1>
<p>With <em>protopipe</em> it is possible to build estimation models for both particle
energy and gamma/hadron classification.
The base classes are defined in the <code class="docutils literal notranslate"><span class="pre">protopipe.mva</span></code> module (see <a class="reference internal" href="../mva/index.html#mva"><span class="std std-ref">mva</span></a>).</p>
<p>For both cases, building a regressor or a classifier, the script
<code class="docutils literal notranslate"><span class="pre">protopipe.scripts.build_model.py</span></code> is used.</p>
<p>The following is the help output which shows required arguments and options.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&gt;$ protopipe-MODEL -h
usage: protopipe-MODEL [-h] --config_file CONFIG_FILE [--max_events MAX_EVENTS] [--wave | --tail]
                   (--cameras_from_config | --cameras_from_file | --cam_id_list CAM_ID_LIST) [-i INDIR] [--infile_signal INFILE_SIGNAL]
                   [--infile_background INFILE_BACKGROUND] [-o OUTDIR]

Build model for regression/classification

optional arguments:
  -h, --help            show this help message and exit
  --config_file CONFIG_FILE
  --max_events MAX_EVENTS
                        maximum number of events to use
  --wave                if set, use wavelet cleaning
  --tail                if set, use tail cleaning (default), otherwise wavelets
  --cameras_from_config
                        Get cameras configuration file (Priority 1)
  --cameras_from_file   Get cameras from input file (Priority 2)
  --cam_id_list CAM_ID_LIST
                        Select cameras like &#39;LSTCam CHEC&#39; (Priority 3)
  -i INDIR, --indir INDIR
                        Directory containing the required input file(s)
  --infile_signal INFILE_SIGNAL
                        SIGNAL file (default: read from config file)
  --infile_background INFILE_BACKGROUND
                        BACKGROUND file (default: read from config file)
  -o OUTDIR, --outdir OUTDIR
</pre></div>
</div>
<p>The script takes along its arguments a configuration file which depends on what
type of model needs to be built.</p>
<p>The available choices can be found under <code class="docutils literal notranslate"><span class="pre">`protopipe.aux.example_config_files`</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">AdaBoostRegressor.yaml</span></code> is used to train an energy regressor,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">RandomForestRegressor.yaml</span></code>  is used to train an energy regressor,</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">RandomForestClassifier.yaml</span></code> is used to train a gamma/hadron classifier.</p></li>
</ul>
<div class="section" id="energy-regressor">
<h2>Energy regressor<a class="headerlink" href="#energy-regressor" title="Permalink to this headline">¶</a></h2>
<p>To build this you need a table with at least the MC energy (the target)
and some event characteristics (the features) to reconstruct the energy.
This table is created in the <a class="reference internal" href="data_training.html#data-training"><span class="std std-ref">Data training</span></a> step.</p>
<p>The following is a commented example of the required configuration file
<code class="docutils literal notranslate"><span class="pre">AdaBoostRegressor.yaml</span></code> with similar options as for <code class="docutils literal notranslate"><span class="pre">RandomForestRegressor.yaml</span></code>,</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">General</span><span class="p">:</span>
  <span class="c1"># [...] = your analysis local full path OUTSIDE the Vagrant box</span>
  <span class="nt">data_dir</span><span class="p">:</span> <span class="s">&#39;../../data/&#39;</span>
  <span class="nt">data_sig_file</span><span class="p">:</span> <span class="s">&#39;TRAINING_energy_tail_gamma_merged.h5&#39;</span>
  <span class="nt">outdir</span><span class="p">:</span> <span class="s">&#39;./&#39;</span>

  <span class="c1"># List of cameras to use (you can override this from the CLI)</span>
  <span class="nt">cam_id_list</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&#39;LSTCam&#39;</span><span class="p p-Indicator">,</span> <span class="s">&#39;NectarCam&#39;</span><span class="p p-Indicator">]</span>

<span class="c1"># If train_fraction is 1, all the TRAINING dataset will be used to train the</span>
<span class="c1"># model and benchmarking can only be done from the benchmarking notebook</span>
<span class="c1"># TRAINING/benchmarks_DL2_to_classification.ipynb</span>
<span class="nt">Split</span><span class="p">:</span>
  <span class="nt">train_fraction</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.8</span>
  <span class="nt">use_same_number_of_sig_and_bkg_for_training</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">False</span>  <span class="c1"># Lowest statistics will drive the split</span>

<span class="c1"># Optimize the hyper-parameters of the estimator with a grid search</span>
<span class="c1"># If True parameters should be provided as lists</span>
<span class="c1"># If False the model used will be the unique one based on your the</span>
<span class="nt">GridSearchCV</span><span class="p">:</span>
  <span class="nt">use</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">False</span> <span class="c1"># True or False</span>
  <span class="c1"># if False the following two variables are irrelevant</span>
  <span class="nt">scoring</span><span class="p">:</span> <span class="s">&#39;explained_variance&#39;</span>
  <span class="nt">cv</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>

<span class="nt">Method</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="s">&#39;sklearn.ensemble.AdaBoostRegressor&#39;</span>
  <span class="nt">target_name</span><span class="p">:</span> <span class="s">&#39;true_energy&#39;</span>
  <span class="c1"># Please, see scikit-learn&#39;s API for what each parameter means</span>
  <span class="c1"># NOTE: null == None</span>
  <span class="nt">base_estimator</span><span class="p">:</span>
    <span class="nt">name</span><span class="p">:</span> <span class="s">&#39;sklearn.tree.DecisionTreeRegressor&#39;</span>
    <span class="nt">parameters</span><span class="p">:</span>
      <span class="c1"># NOTE: here we set the parameters relevant for sklearn.tree.DecisionTreeRegressor</span>
      <span class="nt">criterion</span><span class="p">:</span> <span class="s">&quot;mse&quot;</span> <span class="c1"># &quot;mse&quot;, &quot;friedman_mse&quot;, &quot;mae&quot; or &quot;poisson&quot;</span>
      <span class="nt">splitter</span><span class="p">:</span> <span class="s">&quot;best&quot;</span> <span class="c1"># &quot;best&quot; or &quot;random&quot;</span>
      <span class="nt">max_depth</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span> <span class="c1"># null or integer</span>
      <span class="nt">min_samples_split</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span> <span class="c1"># integer or float</span>
      <span class="nt">min_samples_leaf</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span> <span class="c1"># int or float</span>
      <span class="nt">min_weight_fraction_leaf</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span> <span class="c1"># float</span>
      <span class="nt">max_features</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span> <span class="c1"># null, &quot;auto&quot;, &quot;sqrt&quot;, &quot;log2&quot;, int or float</span>
      <span class="nt">max_leaf_nodes</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span> <span class="c1"># null or integer</span>
      <span class="nt">min_impurity_decrease</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span> <span class="c1"># float</span>
      <span class="nt">random_state</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span> <span class="c1"># null or integer or RandomState</span>
      <span class="nt">ccp_alpha</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span> <span class="c1"># non-negative float</span>
  <span class="nt">tuned_parameters</span><span class="p">:</span>
    <span class="nt">n_estimators</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>
    <span class="nt">learning_rate</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
    <span class="nt">loss</span><span class="p">:</span> <span class="s">&#39;linear&#39;</span> <span class="c1"># &#39;linear&#39;, &#39;square&#39; or &#39;exponential&#39;</span>
    <span class="nt">random_state</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span> <span class="c1"># int, RandomState instance or None</span>

<span class="c1"># List of the features to use to train the model</span>
<span class="c1"># You can:</span>
<span class="c1"># - comment/uncomment the ones you see here,</span>
<span class="c1"># - add new ones here if they can be evaluated with pandas.DataFrame.eval</span>
<span class="c1"># - if not you can propose modifications to protopipe.mva.utils.prepare_data</span>
<span class="nt">FeatureList</span><span class="p">:</span>
  <span class="nt">Basic</span><span class="p">:</span> <span class="c1"># single-named, they need to correspond to input data columns</span>
  <span class="p p-Indicator">-</span> <span class="s">&#39;h_max&#39;</span>         <span class="c1"># Height of shower maximum from stereoscopic reconstruction</span>
  <span class="p p-Indicator">-</span> <span class="s">&#39;impact_dist&#39;</span>   <span class="c1"># Impact parameter from stereoscopic reconstruction</span>
  <span class="p p-Indicator">-</span> <span class="s">&#39;hillas_width&#39;</span>  <span class="c1"># Image Width</span>
  <span class="p p-Indicator">-</span> <span class="s">&#39;hillas_length&#39;</span> <span class="c1"># Image Length</span>
  <span class="c1"># - &#39;concentration_pixel&#39; # Percentage of photo-electrons in the brightest pixel</span>
  <span class="p p-Indicator">-</span> <span class="s">&#39;leakage_intensity_width_1_reco&#39;</span> <span class="c1"># fraction of total Intensity which is contained in the outermost pixels of the camera</span>
  <span class="nt">Derived</span><span class="p">:</span> <span class="c1"># custom evaluations of basic features that will be added to the data</span>
    <span class="c1"># column name : expression to evaluate using basic column names</span>
    <span class="nt">log10_WLS</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">log10(hillas_width*hillas_length/hillas_intensity)</span>
    <span class="nt">log10_intensity</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">log10(hillas_intensity)</span>
    <span class="nt">CTAMARS_1</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">(sqrt((hillas_x - az)**2 + (hillas_y - alt)**2))**2</span>
    <span class="nt">CTAMARS_2</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">arctan2(hillas_y - alt, hillas_x - az)</span>

<span class="c1"># These cuts select the input data BEFORE training</span>
<span class="nt">SigFiducialCuts</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="s">&#39;good_image</span><span class="nv"> </span><span class="s">==</span><span class="nv"> </span><span class="s">1&#39;</span>
  <span class="p p-Indicator">-</span> <span class="s">&#39;is_valid</span><span class="nv"> </span><span class="s">==</span><span class="nv"> </span><span class="s">True&#39;</span>
  <span class="p p-Indicator">-</span> <span class="s">&#39;hillas_intensity_reco</span><span class="nv"> </span><span class="s">&gt;</span><span class="nv"> </span><span class="s">0&#39;</span>

<span class="nt">Diagnostic</span><span class="p">:</span>
 <span class="c1"># Energy binning (used for reco and true energy)</span>
 <span class="nt">energy</span><span class="p">:</span>
  <span class="nt">nbins</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">15</span>
  <span class="nt">min</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0125</span>
  <span class="nt">max</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">125</span>
</pre></div>
</div>
<p>To estimate the energy of a gamma-ray, one wants to use the relation between
the charge measured in one camera and the impact distance of the event measured
from the telescope (distance from the shower axis to the telescope).</p>
<p>Up to now, simple features have been used to feed regressors to estimate the
energy, e.g.,</p>
<ul class="simple">
<li><p>the charge,</p></li>
<li><p>the width and the length of the images,</p></li>
<li><p>the impact parameter,</p></li>
<li><p>the height of the shower maximum.</p></li>
</ul>
<p>The algorithm used to reconstruct the energy is a <strong>Boosted Decision Tree (BDT)</strong>.
The tuning of the <em>Random Forest (RF)</em> algorithm was found to be
a bit problematic (20 % energy resolution at all energies).
The important thing to get a good energy estimator is to build trees with high
depth.
The minimal number of events to form an external node was fixed to 10 in order
to obtain a model with a reasonable size (~50MB for  for 200000 evts).
Indeed, allowing the trees to develop deeper would result in massive
files (~500MB for 200000 evts).</p>
</div>
<div class="section" id="g-h-classifier">
<h2>g/h classifier<a class="headerlink" href="#g-h-classifier" title="Permalink to this headline">¶</a></h2>
<p>To build a gamma/hadron classifier you need gamma-ray and proton tables with some
features used to discriminate between gamma and hadrons (electrons are handled later
as a contamination).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>An alternative approach - yet to study - could be to train a classifier with gamma
against a background sample composed of weighted hadrons and weighted electrons.</p>
</div>
<p>The following the example provided by the example configuration file <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier.yaml</span></code>,</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">General</span><span class="p">:</span>
  <span class="c1"># [...] = your analysis local full path OUTSIDE the Vagrant box</span>
  <span class="nt">data_dir</span><span class="p">:</span> <span class="s">&#39;../../data/&#39;</span> <span class="c1"># &#39;[...]/data/TRAINING/for_particle_classification/&#39;</span>
  <span class="nt">data_sig_file</span><span class="p">:</span> <span class="s">&#39;TRAINING_classification_tail_gamma_merged.h5&#39;</span>
  <span class="nt">data_bkg_file</span><span class="p">:</span> <span class="s">&#39;TRAINING_classification_tail_proton_merged.h5&#39;</span>
  <span class="nt">outdir</span><span class="p">:</span> <span class="s">&#39;./&#39;</span> <span class="c1"># [...]/estimators/gamma_hadron_classifier</span>

  <span class="c1"># List of cameras to use (protopipe-MODEL help output for other options)</span>
  <span class="nt">cam_id_list</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&#39;LSTCam&#39;</span><span class="p p-Indicator">,</span> <span class="s">&#39;NectarCam&#39;</span><span class="p p-Indicator">]</span>

<span class="c1"># If train_fraction is 1, all the TRAINING dataset will be used to train the</span>
<span class="c1"># model and benchmarking can only be done from the benchmarking notebook</span>
<span class="c1"># TRAINING/benchmarks_DL2_to_classification.ipynb</span>
<span class="nt">Split</span><span class="p">:</span>
  <span class="nt">train_fraction</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.8</span>
  <span class="nt">use_same_number_of_sig_and_bkg_for_training</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">False</span>  <span class="c1"># Lowest statistics will drive the split</span>

<span class="c1"># Optimize the hyper-parameters of the estimator with a grid search</span>
<span class="c1"># If &#39;True&#39; parameters should be provided as lists (for None use [null])</span>
<span class="c1"># If &#39;False&#39; the model used will be the unique one based on your the</span>
<span class="nt">GridSearchCV</span><span class="p">:</span>
  <span class="nt">use</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">False</span> <span class="c1"># &#39;True&#39; or &#39;False&#39;</span>
  <span class="c1"># if False the following to variables are irrelevant</span>
  <span class="nt">scoring</span><span class="p">:</span> <span class="s">&#39;roc_auc&#39;</span>
  <span class="nt">cv</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>

<span class="c1"># Definition of the algorithm/method used and its hyper-parameters</span>
<span class="nt">Method</span><span class="p">:</span>
  <span class="nt">name</span><span class="p">:</span> <span class="s">&#39;sklearn.ensemble.RandomForestClassifier&#39;</span> <span class="c1"># DO NOT CHANGE</span>
  <span class="nt">target_name</span><span class="p">:</span> <span class="s">&#39;label&#39;</span> <span class="c1"># defined between 0 and 1 (DO NOT CHANGE)</span>
  <span class="nt">tuned_parameters</span><span class="p">:</span>
    <span class="c1"># Please, see scikit-learn&#39;s API for what each parameter means</span>
    <span class="c1"># WARNING: null (not a string) == &#39;None&#39;</span>
    <span class="nt">n_estimators</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">100</span> <span class="c1"># integer</span>
    <span class="nt">criterion</span><span class="p">:</span> <span class="s">&#39;gini&#39;</span> <span class="c1"># &#39;gini&#39; or &#39;entropy&#39;</span>
    <span class="nt">max_depth</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span> <span class="c1"># null or integer</span>
    <span class="nt">min_samples_split</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span> <span class="c1"># integer or float</span>
    <span class="nt">min_samples_leaf</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span> <span class="c1"># integer or float</span>
    <span class="nt">min_weight_fraction_leaf</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span> <span class="c1"># float</span>
    <span class="nt">max_features</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">3</span> <span class="c1"># &#39;auto&#39;, &#39;sqrt&#39;, &#39;log2&#39;, integer or float</span>
    <span class="nt">max_leaf_nodes</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span> <span class="c1"># null or integer</span>
    <span class="nt">min_impurity_decrease</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span> <span class="c1"># float</span>
    <span class="nt">bootstrap</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">False</span> <span class="c1"># True or False</span>
    <span class="nt">oob_score</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">False</span> <span class="c1"># True or False</span>
    <span class="nt">n_jobs</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span> <span class="c1"># null or integer</span>
    <span class="nt">random_state</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span> <span class="c1"># null or integer or RandomState</span>
    <span class="nt">verbose</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span> <span class="c1"># integer</span>
    <span class="nt">warm_start</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">False</span> <span class="c1"># &#39;True&#39; or &#39;False&#39;</span>
    <span class="nt">class_weight</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span> <span class="c1"># &#39;balanced&#39;, &#39;balanced_subsample&#39;, null, dict or list of dicts</span>
    <span class="nt">ccp_alpha</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span> <span class="c1"># non-negative float</span>
    <span class="nt">max_samples</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">null</span> <span class="c1"># null, integer or float</span>
  <span class="nt">calibrate_output</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">False</span>  <span class="c1"># If True calibrate model on test data</span>

<span class="c1"># List of the features to use to train the model</span>
<span class="c1"># You can:</span>
<span class="c1"># - comment/uncomment the ones you see here,</span>
<span class="c1"># - add new ones here if they can be evaluated with pandas.DataFrame.eval</span>
<span class="c1"># - if not you can propose modifications to protopipe.mva.utils.prepare_data</span>
<span class="nt">FeatureList</span><span class="p">:</span>
  <span class="nt">Basic</span><span class="p">:</span> <span class="c1"># single-named, they need to correspond to input data columns</span>
  <span class="p p-Indicator">-</span> <span class="s">&#39;h_max&#39;</span>         <span class="c1"># Height of shower maximum from stereoscopic reconstruction</span>
  <span class="p p-Indicator">-</span> <span class="s">&#39;impact_dist&#39;</span>   <span class="c1"># Impact parameter from stereoscopic reconstruction</span>
  <span class="p p-Indicator">-</span> <span class="s">&#39;hillas_width&#39;</span>  <span class="c1"># Image Width</span>
  <span class="p p-Indicator">-</span> <span class="s">&#39;hillas_length&#39;</span> <span class="c1"># Image Length</span>
  <span class="c1"># - &#39;concentration_pixel&#39; # Percentage of photo-electrons in the brightest pixel</span>
  <span class="nt">Derived</span><span class="p">:</span> <span class="c1"># custom evaluations of basic features that will be added to the data</span>
    <span class="c1"># column name : expression to evaluate using basic column names</span>
    <span class="nt">log10_intensity</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">log10(hillas_intensity)</span>
    <span class="nt">log10_energy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">log10(reco_energy)</span> <span class="c1"># Averaged-estimated energy of the shower</span>
    <span class="nt">log10_energy_tel</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">log10(reco_energy_tel)</span> <span class="c1"># Estimated energy of the shower per telescope</span>

<span class="c1"># These cuts select the input data BEFORE training</span>
<span class="nt">SigFiducialCuts</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="s">&#39;good_image</span><span class="nv"> </span><span class="s">==</span><span class="nv"> </span><span class="s">1&#39;</span>
  <span class="p p-Indicator">-</span> <span class="s">&#39;is_valid</span><span class="nv"> </span><span class="s">==</span><span class="nv"> </span><span class="s">True&#39;</span>
  <span class="p p-Indicator">-</span> <span class="s">&#39;hillas_intensity_reco</span><span class="nv"> </span><span class="s">&gt;</span><span class="nv"> </span><span class="s">0&#39;</span>

<span class="nt">BkgFiducialCuts</span><span class="p">:</span>
 <span class="p p-Indicator">-</span> <span class="s">&#39;good_image</span><span class="nv"> </span><span class="s">==</span><span class="nv"> </span><span class="s">1&#39;</span>
 <span class="p p-Indicator">-</span> <span class="s">&#39;is_valid</span><span class="nv"> </span><span class="s">==</span><span class="nv"> </span><span class="s">True&#39;</span>
 <span class="p p-Indicator">-</span> <span class="s">&#39;hillas_intensity_reco</span><span class="nv"> </span><span class="s">&gt;</span><span class="nv"> </span><span class="s">0&#39;</span>

<span class="nt">Diagnostic</span><span class="p">:</span>
 <span class="c1"># Energy binning (used for reco and true energy)</span>
 <span class="nt">energy</span><span class="p">:</span>
  <span class="nt">nbins</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
  <span class="nt">min</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0125</span>
  <span class="nt">max</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">200</span>
</pre></div>
</div>
<p>We want to exploit parameters showing statistical differences in the shower
developments between gamma-ray induced showers and hadron induced shower.
Up to now, we used the second moments of the images (width and length) as well
as the higher orders of the images (skewness and kurtosis which do not show a very high
separation power). We also use stereoscopic parameters such as the heigh of
the shower maximum and the reconstructed energy. The energy is important
since the distribution of the discriminant parameters vary a lot with
the energy of the particles.</p>
<p>Since in the end we want to average the score of the particles between different
cameras, we need the classifier to have an output normalised between 0 and 1.
Ideally, we would like also to get a <a class="reference external" href="https://scikit-learn.org/stable/modules/calibration.html">probabilistic classifier</a> (e.g. score of
0.8 gives a chance probability of 80 % that we are dealing with a signal event).
in order to average one pear with one pear (not an apple), but it’s not so easy
since a lot a of cuts are done afterwards (angular cut, energy cut) which then
make the calibration caduc.</p>
<p>Anyway, we gave up on the BDT method since the output is not easy to normalise
between 0 and 1 (there are also fluctuations on the score distribution
that can totally crash the normalisation) and we trained a Random Forest (RF) as
people do the MARS analysis in CTA (not the same way as in MAGIC, e.g.
information of tel #1 and #2 in the same RF, here one model per type of telescope
then gammaness averaging).</p>
<p>Once again, the main important hyper-parameters
to get a robust classifier is the maximal depth of the trees and the
minimal number of events to get an external node (<cite>min_samples_leaf</cite>).
Please be aware that if you specify a <cite>min_samples_leaf</cite> close to one you’ll be
in a high regime of overtraining that can be seen with an area under
the ROC (auc) of 1 for the training sample and a mismatch between the gammaness
distribution of the training and the test samples. In order to get an agreement
(by eye, could do a KS/chi2 test) between the training and test distributions
I chose to grow a forest of 200 trees with a max_depth of 10. I use a maximal
number of 200000 images for each sample for the training/test phase.</p>
<p>Note that the previous setup differ from what Abelardo is doing. Abelardo has
no max_depth, he grows 100 tress, and uses a min_samples_leaf close to 1 (TBC).
He is in an overtraining regime (auc ROC close to 1) and the agreement of the
distributions between the training and the test samples is bad. This is not good
since one might want to control the cut efficiencies of the models and
in real conditions to see that everything is correct.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The default settings used are not yet optimised for every case.</p>
<p>They have been tuned to get reasonable performance and a good agreeement
between the training/test samples.</p>
<p>A first optimisation will follow from the comparison against CTA-MARS, even
though the parameters used and settings are already the same.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="model_diagnostics.html" class="btn btn-neutral float-right" title="Models diagnostics" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="data_training.html" class="btn btn-neutral float-left" title="Data training" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, Michele Peresano.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove input cells at runtime (nbsphinx)\n",
    "import IPython.core.display as d\n",
    "d.display_html('<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>', raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy reconstruction (MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommended datasample(s):** model file, train and test data produced with ``protopipe-MODEL``\n",
    "\n",
    "**Data level(s):** DL1b (telescope-wise image parameters) + DL2 (only shower geometry)\n",
    "\n",
    "**Description:**\n",
    "\n",
    "It should be used to test the performance of the trained model **before** use it to estimate the energy of DL2 events.\n",
    "\n",
    "In fact, what happens in a *protopipe* analysis is that part of the TRAINING sample can be used for *testing* the models to get some preliminary diagnostics (i.e. before launching the much heavier DL2 production).\n",
    "\n",
    "This notebook shows a camera-wise preliminary diagnostics.\n",
    "\n",
    "Settings and setup of the plots are done using the same configuration file used for training the model.\n",
    "\n",
    "**Requirements and steps to reproduce:**\n",
    "\n",
    "- produce the model with ``protopipe-MODEL``\n",
    "\n",
    "- Execute the notebook ``protopipe-BENCHMARK``,\n",
    "\n",
    "``protopipe-BENCHMARK launch --config_file configs/benchmarks.yaml -n TRAINING/benchmarks_MODELS_energy``\n",
    "\n",
    "To obtain the list of all available parameters add ``--help-notebook``.\n",
    "\n",
    "**Developers**  \n",
    "\n",
    "Please, if you have any contribution regarding this part, do it here and not in the relevant sections of the main code, which are now discontinued (they could be migrated back into ``protopipe.mva`` or in another place when more stable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Feature importance](#Feature-importance)\n",
    "* [Feature distributions](#Feature-distributions)\n",
    "* [Migration distribution](#Migration-distribution)\n",
    "* [Energy resolution and bias](#Energy-resolution-and-bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "remove_input"
    ]
   },
   "source": [
    "## Imports\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import joblib\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import astropy.units as u\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import binned_statistic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "#import seaborn as sns\n",
    "#sns.set_context(\"talk\")\n",
    "\n",
    "from protopipe.pipeline.utils import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "remove_input"
    ]
   },
   "source": [
    "## Functions and classes\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obj(name ):\n",
    "    \"\"\"Load object in binary\"\"\"\n",
    "    with gzip.open(name, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(ax, data, nbin, limit, norm=False, yerr=False, hist_kwargs={}, error_kw={}):\n",
    "    \"\"\"Utility function to plot histogram\"\"\"\n",
    "    bin_edges = np.linspace(limit[0], limit[-1], nbin + 1, True)\n",
    "    y, tmp = np.histogram(data, bins=bin_edges)\n",
    "    weights = np.ones_like(y)\n",
    "    if norm is True:\n",
    "        weights = weights / float(np.sum(y))\n",
    "    if yerr is True:\n",
    "        yerr = np.sqrt(y) * weights\n",
    "    else:\n",
    "        yerr = np.zeros(len(y))\n",
    "\n",
    "    centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "    width = bin_edges[1:] - bin_edges[:-1]\n",
    "    ax.bar(centers, y * weights, width=width, yerr=yerr, error_kw=error_kw, **hist_kwargs)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(suptitle,\n",
    "                       feature_list,\n",
    "                       data_list,\n",
    "                       nbin=30,\n",
    "                       hist_kwargs_list={},\n",
    "                       error_kw_list={},\n",
    "                       ncols=2):\n",
    "    \"\"\"Plot feature distributions for several data set. Returns list of axes.\"\"\"\n",
    "    n_feature = len(feature_list)\n",
    "    nrows = int(n_feature / ncols) if n_feature % ncols == 0 else int((n_feature + 1) / ncols)\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(5 * ncols, 5 * nrows))\n",
    "    plt.suptitle(suptitle)\n",
    "    if nrows == 1 and ncols == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for i, colname in enumerate(feature_list):\n",
    "        ax = axes[i]\n",
    "\n",
    "        for j, data in enumerate(data_list):\n",
    "            if colname in [\"hillas_intensity\", \"h_max\", \"impact_dist\"]: # automatically log these quantities for clarity\n",
    "                # Range for binning\n",
    "                range_min = min([np.log10(data[colname]).min() for data in data_list])\n",
    "                range_max = max([np.log10(data[colname]).max() for data in data_list])\n",
    "                myrange = [range_min, range_max]\n",
    "        \n",
    "                ax = plot_hist(\n",
    "                    ax=ax, data=np.log10(data[colname]), nbin=nbin, limit=myrange,\n",
    "                    norm=True, yerr=True,\n",
    "                    hist_kwargs=hist_kwargs_list[j],\n",
    "                    error_kw=error_kw_list[j]\n",
    "                )\n",
    "                ax.set_xlabel(f\"log10({colname})\")\n",
    "            else:\n",
    "                range_min = min([data[colname].min() for data in data_list])\n",
    "                range_max = max([data[colname].max() for data in data_list])\n",
    "                myrange = [range_min, range_max]\n",
    "                \n",
    "                ax = plot_hist(\n",
    "                    ax=ax, data=data[colname], nbin=nbin, limit=myrange,\n",
    "                    norm=True, yerr=True,\n",
    "                    hist_kwargs=hist_kwargs_list[j],\n",
    "                    error_kw=error_kw_list[j]\n",
    "                )\n",
    "\n",
    "                ax.set_xlabel(colname)\n",
    "\n",
    "        ax.set_ylabel('Arbitrary units')\n",
    "        ax.legend(loc='upper left')\n",
    "        ax.grid()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evt_subarray_model_output(data,\n",
    "                                  weight_name=\"reco_energy_tel_weigth\",\n",
    "                                  keep_cols=['reco_energy'],\n",
    "                                  model_output_name='reco_energy_tel',\n",
    "                                  model_output_name_evt='reco_energy'):\n",
    "    \"\"\"\n",
    "    Returns DataStore with keepcols + score/target columns of model at the\n",
    "    level-subarray-event.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: `~pandas.DataFrame`\n",
    "        Data frame\n",
    "    weight_name: `str`\n",
    "        Variable name in data frame to weight events with\n",
    "    keep_cols: `list`, optional\n",
    "        List of variables to keep in resulting data frame\n",
    "    model_output_name: `str`, optional\n",
    "        Name of model output (image level)\n",
    "    model_output_name: `str`, optional\n",
    "        Name of averaged model output (event level)\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    data: `~pandas.DataFrame`\n",
    "        Data frame\n",
    "    \"\"\"\n",
    "\n",
    "    keep_cols += [model_output_name]\n",
    "    keep_cols += [weight_name]\n",
    "    new_data = data[keep_cols].copy(deep=True)\n",
    "\n",
    "    new_data[model_output_name_evt] = np.zeros(len(new_data))\n",
    "    new_data.set_index([\"tel_id\"], append=True, inplace=True)\n",
    "\n",
    "    new_data[model_output_name_evt] = new_data.groupby([\"obs_id\", \"event_id\"]).apply(\n",
    "        lambda g: np.average(g[model_output_name], weights=g[weight_name])\n",
    "    )\n",
    "\n",
    "    # Remove columns\n",
    "    #new_data = new_data.drop(columns=[model_output_name])\n",
    "\n",
    "    # Remove duplicates\n",
    "    new_data = new_data[~new_data.index.duplicated(keep=\"first\")]\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelDiagnostic(object):\n",
    "    \"\"\"\n",
    "    Base class for model diagnostics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: `~sklearn.base.BaseEstimator`\n",
    "        Best model\n",
    "    feature_name_list: list\n",
    "        List of the features used to buil the model\n",
    "    target_name: str\n",
    "        Name of the target (e.g. score, gamaness, energy, etc.)\n",
    "    \"\"\"\n",
    "    def __init__(self, model, feature_name_list, target_name):\n",
    "        self.model = model\n",
    "        self.feature_name_list = feature_name_list\n",
    "        self.target_name = target_name\n",
    "\n",
    "    def plot_feature_importance(self, ax, **kwargs):\n",
    "        \"\"\"\n",
    "        Plot importance of features\n",
    "        Parameters\n",
    "        ----------\n",
    "        ax: `~matplotlib.axes.Axes`\n",
    "            Axis\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            import matplotlib.pyplot as plt\n",
    "            ax = plt.gca()\n",
    "\n",
    "        importance = self.model.feature_importances_\n",
    "        importance, feature_labels = \\\n",
    "            zip(*sorted(zip(importance, self.feature_name_list), reverse=True))\n",
    "\n",
    "        bin_edges = np.arange(0, len(importance)+1)\n",
    "        bin_width = bin_edges[1:] - bin_edges[:-1] - 0.1\n",
    "\n",
    "        ax.bar(bin_edges[:-1], importance, width=bin_width, **kwargs)\n",
    "        ax.set_xticks(np.arange(0, len(importance)))\n",
    "        ax.set_xticklabels(feature_labels, rotation=75)\n",
    "\n",
    "        return ax\n",
    "\n",
    "    def plot_features(self,\n",
    "                      suptitle,\n",
    "                      data_list,\n",
    "                      nbin=30,\n",
    "                      hist_kwargs_list={},\n",
    "                      error_kw_list={},\n",
    "                      ncols=2):\n",
    "        \"\"\"\n",
    "        Plot model features for different data set (e.g. training and test samples).\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_list: list\n",
    "            List of data\n",
    "        nbin: int\n",
    "            Number of bin\n",
    "        hist_kwargs_list: dict\n",
    "            Dictionary with histogram options\n",
    "        error_kw_list: dict\n",
    "            Dictionary with error bar options\n",
    "        ncols: int\n",
    "            Number of columns\n",
    "        \"\"\"\n",
    "        return plot_distributions(\n",
    "            suptitle,\n",
    "            self.feature_name_list,\n",
    "            data_list,\n",
    "            nbin,\n",
    "            hist_kwargs_list,\n",
    "            error_kw_list, ncols\n",
    "        )\n",
    "\n",
    "    def add_image_model_output(self):\n",
    "        raise NotImplementedError(\"Please Implement this method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressorDiagnostic(ModelDiagnostic):\n",
    "    \"\"\"\n",
    "    Class to plot several diagnostic plots for regression.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: sklearn.base.BaseEstimator\n",
    "        Scikit model\n",
    "    feature_name_list: str\n",
    "        List of features\n",
    "    target_name: str\n",
    "        Name of target (e.g. `mc_energy`)\n",
    "    data_train: `~pandas.DataFrame`\n",
    "        Data frame\n",
    "    data_test: `~pandas.DataFrame`\n",
    "        Data frame\n",
    "    \"\"\"\n",
    "    def __init__(self, model,\n",
    "                 feature_name_list,\n",
    "                 target_name,\n",
    "                 is_target_log,\n",
    "                 data_train,\n",
    "                 data_test,\n",
    "                 output_name,\n",
    "                 estimation_weight):\n",
    "        super().__init__(model, feature_name_list, target_name)\n",
    "\n",
    "        self.data_train = data_train\n",
    "        self.data_test = data_test\n",
    "        self.is_target_log = is_target_log\n",
    "\n",
    "        self.target_estimation_name = self.target_name\n",
    "        self.estimation_weight = estimation_weight\n",
    "\n",
    "        self.output_name = output_name\n",
    "        self.output_name_img = output_name + '_tel'\n",
    "        self.output_weight_img = output_name + '_tel' + \"_weight\" \n",
    "\n",
    "        # Compute and add target estimation\n",
    "        self.data_train = self.add_image_model_output(self.data_train)\n",
    "        self.data_test = self.add_image_model_output(self.data_test)\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_resolution_distribution(ax, y_true, y_reco, nbin=100, fit_range=[-3,3],\n",
    "                                     fit_kwargs={}, hist_kwargs={}):\n",
    "        \"\"\"\n",
    "        Compute bias and resolution with a gaussian fit\n",
    "        and return a plot with the fit results and the migration distribution.\n",
    "        \"\"\"\n",
    "\n",
    "        def gauss(x, ampl, mean, std):\n",
    "            return ampl * np.exp(-0.5 * ((x - mean) / std) ** 2)\n",
    "\n",
    "        if ax is None:\n",
    "            ax = plt.gca()\n",
    "\n",
    "        migration = (y_reco - y_true) / y_true\n",
    "        bin_edges = np.linspace(fit_range[0], fit_range[-1], nbin + 1, True)\n",
    "        y, tmp = np.histogram(migration, bins=bin_edges)\n",
    "        x = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "        try:\n",
    "            param, cov = curve_fit(gauss, x, y)\n",
    "        except:\n",
    "            param = [-1, -1, -1]\n",
    "            cov = [[]]\n",
    "            #print('Not enough stat ? (#evts={})'.format(len(y_true)))\n",
    "\n",
    "        plot_hist(\n",
    "            ax=ax, data=migration, nbin=nbin,\n",
    "            yerr=False,\n",
    "            norm=False,\n",
    "            limit=fit_range,\n",
    "            hist_kwargs=hist_kwargs\n",
    "        )\n",
    "\n",
    "        ax.plot(x, gauss(x, param[0], param[1], param[2]), **fit_kwargs)\n",
    "\n",
    "        return ax, param, cov\n",
    "\n",
    "    def add_image_model_output(self, data):\n",
    "        \n",
    "        features_values = data[features].to_numpy()\n",
    "        \n",
    "        if self.estimation_weight == \"CTAMARS\":\n",
    "            # Get an array of trees\n",
    "            predictions_trees = np.array([tree.predict(features_values) for tree in self.model.estimators_])\n",
    "            v = np.mean(predictions_trees, axis=0)\n",
    "            w = np.std(predictions_trees, axis=0)\n",
    "            if self.is_target_log:\n",
    "                data[self.output_name_img] = 10**v\n",
    "                data[self.output_weight_img] = 10**w\n",
    "            else:\n",
    "                data[self.output_name_img] = v\n",
    "                data[self.output_weight_img] = w\n",
    "        else:\n",
    "            data.eval(f'{self.output_weight_img} = {estimation_weight}', inplace=True)\n",
    "            v = self.model.predict(features_values)\n",
    "            if self.is_target_log:\n",
    "                data[self.output_name_img] = 10**v\n",
    "            else:\n",
    "                data[self.output_name_img] = v\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "remove_input"
    ]
   },
   "source": [
    "## Load models\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "analyses_directory = None\n",
    "analysis_name = None\n",
    "model_configuration_filename = None # Name of the configuration file of the model\n",
    "output_directory = Path.cwd() # default output directory for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the model configuration file has been defined\n",
    "# either from the CLI of from the benchmarks configuration file (default)\n",
    "if model_configuration_filename is None:\n",
    "    try:\n",
    "        model_configuration_filename = model_configuration_filenames[\"energy\"]\n",
    "    except KeyError:\n",
    "        raise ValueError(\"The name of the configuration file is undefined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_configuration_path = Path(analyses_directory) / analysis_name / Path(\"configs/analysis.yaml\")\n",
    "model_configuration_path = Path(analyses_directory) / analysis_name / \"configs\" / model_configuration_filename\n",
    "input_directory = Path(analyses_directory) / analysis_name / Path(\"estimators/energy_regressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration files\n",
    "ana_cfg = load_config(analysis_configuration_path)\n",
    "cfg = load_config(model_configuration_path)\n",
    "\n",
    "# Get info from configs\n",
    "estimation_weight = ana_cfg[\"EnergyRegressor\"][\"estimation_weight\"]\n",
    "model_type = \"regressor\"\n",
    "method_name = cfg[\"Method\"][\"name\"].split(\".\")[-1]\n",
    "is_target_log = cfg[\"Method\"][\"log_10_target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = [model.split('/')[-1].split('_')[1] for model in glob.glob(f\"{input_directory}/{model_type}*.pkl.gz\")]\n",
    "data = {camera : dict.fromkeys([\"model\", \"data_scikit\", \"data_train\", \"data_test\"]) for camera in cameras} \n",
    "\n",
    "for camera in cameras:\n",
    "\n",
    "    data[camera][\"data_scikit\"] = load_obj(\n",
    "                glob.glob(f\"{input_directory}/data_scikit_{model_type}_{method_name}_{camera}.pkl.gz\")[0]\n",
    "                )\n",
    "    data[camera][\"data_train\"] = pd.read_pickle(\n",
    "        glob.glob(f\"{input_directory}/data_train_{model_type}_{method_name}_{camera}.pkl.gz\")[0]\n",
    "                )\n",
    "    data[camera][\"data_test\"] = pd.read_pickle(\n",
    "        glob.glob(f\"{input_directory}/data_test_{model_type}_{method_name}_{camera}.pkl.gz\")[0]\n",
    "    )\n",
    "    \n",
    "    modelName = f\"{model_type}_*_{camera}_{method_name}.pkl.gz\"\n",
    "    data[camera][\"model\"] = joblib.load(glob.glob(f\"{input_directory}/{model_type}_{camera}_{method_name}.pkl.gz\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "remove_input"
    ]
   },
   "source": [
    "## Settings and setup\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy (both true and reconstructed)\n",
    "nbins = cfg[\"Diagnostic\"][\"energy\"][\"nbins\"]\n",
    "energy_edges = np.logspace(\n",
    "        np.log10(cfg[\"Diagnostic\"][\"energy\"][\"min\"]),\n",
    "        np.log10(cfg[\"Diagnostic\"][\"energy\"][\"max\"]),\n",
    "        nbins + 1,\n",
    "        True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_basic = cfg[\"FeatureList\"][\"Basic\"]\n",
    "features_derived = cfg[\"FeatureList\"][\"Derived\"]\n",
    "features = features_basic + list(features_derived)\n",
    "features = sorted(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic = dict.fromkeys(cameras)\n",
    "for camera in cameras:\n",
    "    diagnostic[camera] = RegressorDiagnostic(\n",
    "                    model=data[camera][\"model\"],\n",
    "                    feature_name_list=features,\n",
    "                    target_name=\"true_energy\",\n",
    "                    is_target_log=is_target_log,\n",
    "                    data_train=data[camera][\"data_train\"],\n",
    "                    data_test=data[camera][\"data_test\"],\n",
    "                    output_name=\"reco_energy\",\n",
    "                    estimation_weight=estimation_weight\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we check if a _plots_ folder exists already.  \n",
    "# If not, we create it.\n",
    "plots_folder = Path(output_directory) / \"plots\"\n",
    "plots_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for camera in cameras:\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    ax = plt.gca()\n",
    "    ax = diagnostic[camera].plot_feature_importance(\n",
    "        ax,\n",
    "        **{\"alpha\": 0.7, \"edgecolor\": \"black\", \"linewidth\": 2, \"color\": \"darkgreen\"}\n",
    "    )\n",
    "    ax.set_ylabel(\"Feature importance\")\n",
    "    ax.grid()\n",
    "    plt.title(camera)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plots_folder / f\"energy_model_feature_importance_{camera}_protopipe_{analysis_name}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature distributions\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for camera in cameras:\n",
    "\n",
    "    fig, axes = diagnostic[camera].plot_features(\n",
    "        suptitle=camera,\n",
    "        data_list=[data[camera][\"data_train\"], data[camera][\"data_test\"]],\n",
    "        nbin=30,\n",
    "        hist_kwargs_list=[\n",
    "            {\n",
    "                \"edgecolor\": \"blue\",\n",
    "                \"color\": \"blue\",\n",
    "                \"label\": \"Gamma training\",\n",
    "                \"alpha\": 0.2,\n",
    "                \"fill\": True,\n",
    "                \"ls\": \"-\",\n",
    "                \"lw\": 2,\n",
    "            },\n",
    "            {\n",
    "                \"edgecolor\": \"blue\",\n",
    "                \"color\": \"blue\",\n",
    "                \"label\": \"Gamma test\",\n",
    "                \"alpha\": 1,\n",
    "                \"fill\": False,\n",
    "                \"ls\": \"--\",\n",
    "                \"lw\": 2,\n",
    "            },\n",
    "        ],\n",
    "        error_kw_list=[\n",
    "            dict(ecolor=\"blue\", lw=2, capsize=2, capthick=2, alpha=0.2),\n",
    "            dict(ecolor=\"blue\", lw=2, capsize=2, capthick=2, alpha=0.2),\n",
    "        ],\n",
    "        ncols=5,\n",
    "    )\n",
    "    plt.savefig(plots_folder / f\"energy_model_feature_distributions_{camera}_protopipe_{analysis_name}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Migration distribution\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING:** here we naively applying a gaussian fit for each slice in true energy, but it is not the best way especially for the lowest and highest bins (because of intrisinc tails in the ditributions and lower statistics respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for camera in cameras:\n",
    "\n",
    "    ncols = 5\n",
    "    nrows = (\n",
    "        int(nbins / ncols) if nbins % ncols == 0 else int((nbins + 1) / ncols)\n",
    "    )\n",
    "    if nrows == 0:\n",
    "        nrows = 1\n",
    "        ncols = 1\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(5 * 5, 10))\n",
    "    plt.suptitle(camera)\n",
    "    try:\n",
    "        axes = axes.flatten()\n",
    "    except:\n",
    "        axes = [axes]\n",
    "\n",
    "    bias = []\n",
    "    resolution = []\n",
    "    energy_centres = []\n",
    "\n",
    "    for ibin in range(len(energy_edges) - 1):\n",
    "        ax = axes[ibin]\n",
    "        \n",
    "        test_data = diagnostic[camera].data_test.query(\n",
    "            \"true_energy >= {} and true_energy < {}\".format(\n",
    "                energy_edges[ibin], energy_edges[ibin + 1]\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # print(\"Estimate energy for {} evts\".format(len(test_data)))\n",
    "\n",
    "        er = test_data[\"reco_energy_tel\"]\n",
    "        emc = test_data[\"true_energy\"]\n",
    "\n",
    "        opt_hist = {\n",
    "            \"edgecolor\": \"black\",\n",
    "            \"color\": \"darkgreen\",\n",
    "            \"label\": \"data\",\n",
    "            \"alpha\": 0.7,\n",
    "            \"fill\": True,\n",
    "        }\n",
    "        opt_fit = {\"c\": \"red\", \"lw\": 2, \"label\": \"Best fit\"}\n",
    "        ax, fit_param, cov = diagnostic[camera].plot_resolution_distribution(\n",
    "            ax=ax,\n",
    "            y_true=emc,\n",
    "            y_reco=er,\n",
    "            nbin=50,\n",
    "            fit_range=[-2, 2],\n",
    "            hist_kwargs=opt_hist,\n",
    "            fit_kwargs=opt_fit,\n",
    "        )\n",
    "        if fit_param[2] < 0:  # negative value are allowed for the fit\n",
    "            fit_param[2] *= -1\n",
    "\n",
    "        label = \"[{:.2f},{:.2f}] TeV\\n#Evts={}\\nmean={:.2f}\\nstd={:.2f}\".format(\n",
    "            energy_edges[ibin],\n",
    "            energy_edges[ibin + 1],\n",
    "            len(er),\n",
    "            fit_param[1],\n",
    "            fit_param[2],\n",
    "        )\n",
    "\n",
    "        ax.set_ylabel(\"# Events\")\n",
    "        ax.set_xlabel(\"(E_reco - E_true) / E_true\")\n",
    "        ax.set_xlim([-2, 2])\n",
    "        ax.grid()\n",
    "\n",
    "        evt_patch = mpatches.Patch(color=\"white\", label=label)\n",
    "        data_patch = mpatches.Patch(color=\"blue\", label=\"data\")\n",
    "        fit_patch = mpatches.Patch(color=\"red\", label=\"best fit\")\n",
    "        ax.legend(loc=\"best\", handles=[evt_patch, data_patch, fit_patch])\n",
    "        plt.tight_layout()\n",
    "\n",
    "        #print(\n",
    "        #    \" Fit results: ({:.3f},{:.3f} TeV)\".format(\n",
    "        #        energy_edges[ibin], energy_edges[ibin + 1]\n",
    "        #    )\n",
    "        #)\n",
    "\n",
    "        #try:\n",
    "        #    print(\" - A    : {:.3f} +/- {:.3f}\".format(fit_param[0], cov[0][0]))\n",
    "        #    print(\" - mean : {:.3f} +/- {:.3f}\".format(fit_param[1], cov[1][1]))\n",
    "        #    print(\" - std  : {:.3f} +/- {:.3f}\".format(fit_param[2], cov[2][2]))\n",
    "        #except:\n",
    "        #    print(\" ==> Problem with fit, no covariance...\".format())\n",
    "        #    continue\n",
    "\n",
    "        bias.append(fit_param[1])\n",
    "        resolution.append(fit_param[2])\n",
    "        energy_centres.append(\n",
    "            (energy_edges[ibin] + energy_edges[ibin + 1]) / 2.0\n",
    "        )\n",
    "\n",
    "    plt.savefig(plots_folder / f\"energy_model_migration_distributions_{camera}_protopipe_{analysis_name}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy resolution and bias\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_energy_bins_edges = np.linspace(\n",
    "        np.log10(cfg[\"Diagnostic\"][\"energy\"][\"min\"]),\n",
    "        np.log10(cfg[\"Diagnostic\"][\"energy\"][\"max\"]),\n",
    "        nbins + 1,\n",
    "        True,\n",
    "    ) * u.TeV\n",
    "\n",
    "true_energy_bins_centers = 0.5 * (true_energy_bins_edges[1:]+true_energy_bins_edges[:-1])\n",
    "\n",
    "for camera in cameras:\n",
    "    \n",
    "    plt.figure(figsize=(9,7))\n",
    "\n",
    "    reco_energy = diagnostic[camera].data_test[diagnostic[camera].output_name_img]\n",
    "    true_energy = diagnostic[camera].data_test[diagnostic[camera].target_estimation_name]\n",
    "    \n",
    "    resolution = binned_statistic(np.log10(true_energy),\n",
    "                              reco_energy/true_energy - 1,\n",
    "                              statistic = lambda x: np.percentile(np.abs(x), 68),\n",
    "                              bins=true_energy_bins_edges)\n",
    "\n",
    "    corr_resolution_mean = binned_statistic(np.log10(true_energy),\n",
    "                                  reco_energy/true_energy - 1,\n",
    "                                  statistic = lambda x: np.percentile(np.abs(x-np.mean(x)), 68),\n",
    "                                  bins=true_energy_bins_edges)\n",
    "    \n",
    "    corr_resolution_median = binned_statistic(np.log10(true_energy),\n",
    "                                  reco_energy/true_energy - 1,\n",
    "                                  statistic = lambda x: np.percentile(np.abs(x-np.median(x)), 68),\n",
    "                                  bins=true_energy_bins_edges)\n",
    "    \n",
    "    bias_mean = binned_statistic(np.log10(true_energy), \n",
    "                        reco_energy/true_energy - 1, \n",
    "                        statistic=\"mean\", \n",
    "                        bins=true_energy_bins_edges)\n",
    "    \n",
    "    bias_median = binned_statistic(np.log10(true_energy), \n",
    "                        reco_energy/true_energy - 1, \n",
    "                        statistic=\"median\", \n",
    "                        bins=true_energy_bins_edges)\n",
    "    \n",
    "    plt.plot(true_energy_bins_centers, resolution[0], label=\"resolution (bias included)\")\n",
    "    plt.plot(true_energy_bins_centers, corr_resolution_mean[0], label=\"resolution (bias mean corrected)\")\n",
    "    plt.plot(true_energy_bins_centers, corr_resolution_median[0], label=\"resolution (bias median corrected)\")\n",
    "    plt.plot(true_energy_bins_centers, bias_mean[0], label=\"bias (mean)\")\n",
    "    plt.plot(true_energy_bins_centers, bias_median[0], label=\"bias (median)\")\n",
    "    plt.title(camera)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.ylim(-0.2, 1.2)\n",
    "    plt.xlim(np.log10(0.0125), np.log10(125))\n",
    "    plt.xlabel('log10(true energy) [TeV]')\n",
    "\n",
    "    plt.savefig(plots_folder / f\"energy_model_resolution_bias_{camera}_protopipe_{analysis_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

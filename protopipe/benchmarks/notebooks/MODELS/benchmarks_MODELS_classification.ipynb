{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove input cells at runtime (nbsphinx)\n",
    "import IPython.core.display as d\n",
    "d.display_html('<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>', raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle classification (MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommended datasample(s):** model file, train and test data produced with ``protopipe-MODEL``\n",
    "\n",
    "**Data level(s):** DL1b (telescope-wise image parameters) + DL2 (shower geometry and estimated energy)\n",
    "\n",
    "**Description:**\n",
    "\n",
    "Test the performance of the trained model **before** use it to estimate the particle type of DL2 events.  \n",
    "In a *protopipe* analysis part of the TRAINING sample is used for *testing* the models to get some preliminary diagnostics (i.e. before launching the much heavier DL2 production).  \n",
    "Note that this notebook shows a camera-wise preliminary diagnostics (since one model is produced per-camera): this means that the model output considered here is the _telescope-wise_ quantity and not the _event-wise_ one which is instead benchmarked at a subsequent step.  \n",
    "Settings and setup of the plots are done using the same configuration file used for training the model.\n",
    "\n",
    "**Requirements and steps to reproduce:**\n",
    "\n",
    "- produce the model with ``protopipe-MODEL``\n",
    "\n",
    "- Execute the notebook ``protopipe-BENCHMARK``,\n",
    "\n",
    "``protopipe-BENCHMARK launch --config_file configs/benchmarks.yaml -n TRAINING/benchmarks_MODELS_classification``\n",
    "\n",
    "To obtain the list of all available parameters add ``--help-notebook``.\n",
    "\n",
    "**Development and testing:**  \n",
    "\n",
    "As with any other part of _protopipe_ and being part of the official repository, this notebook can be further developed by any interested contributor.   \n",
    "The execution of this notebook is not currently automatic, it must be done locally by the user _before_ pushing a pull-request.  \n",
    "Please, strip the output before pushing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "* [Feature importance](#Feature-importance)\n",
    "* [Feature distributions](#Feature-distributions)\n",
    "* [Boosted Decision Tree Error rate](#Boosted-Decision-Tree-Error-rate)\n",
    "* [Model output](#Model-output)\n",
    "* [Energy-dependent distributions](#Energy-dependent-distributions)\n",
    "* [Energy-dependent ROC curves](#ROC-curve-variation-on-test-sample)\n",
    "* [AUC as a function of reconstructed energy](#AUC-as-a-function-of-reconstructed-energy)\n",
    "* [Precision-Recall](#Precision-Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "remove_input"
    ]
   },
   "source": [
    "## Imports\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.pyplot import rc\n",
    "import matplotlib.style as style\n",
    "from cycler import cycler\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "\n",
    "from protopipe.pipeline.io import load_config, load_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "hide_cell",
     "remove_input"
    ]
   },
   "source": [
    "## Functions and classes\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move to protopipe.benchmarks.utils\n",
    "def string_to_boolean(variables):\n",
    "    \"\"\"Convert True/False strings to booleans.\n",
    "    \n",
    "    Useful in case a specific use of the CLI doesn't allow to read booleans as booleans.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    variables: list of str\n",
    "        Variables to check.\n",
    "    \"\"\"\n",
    "    \n",
    "    def check_str(x): return x if type(x) == bool \\\n",
    "        else True if x == \"True\" \\\n",
    "        else False if x == \"False\" \\\n",
    "        else raise_(ValueError(f\"{x} is not a valid boolean.\"))\n",
    "    \n",
    "    return list(map(check_str, variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(ax, data, nbin, limit, norm=False, yerr=False, hist_kwargs={}, error_kw={}):\n",
    "    \"\"\"Utility function to plot histogram\"\"\"\n",
    "    bin_edges = np.linspace(limit[0], limit[-1], nbin + 1, True)\n",
    "    y, tmp = np.histogram(data, bins=bin_edges)\n",
    "    weights = np.ones_like(y)\n",
    "    if norm is True:\n",
    "        weights = weights / float(np.sum(y))\n",
    "    if yerr is True:\n",
    "        yerr = np.sqrt(y) * weights\n",
    "    else:\n",
    "        yerr = np.zeros(len(y))\n",
    "\n",
    "    centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "    width = bin_edges[1:] - bin_edges[:-1]\n",
    "    ax.bar(centers, y * weights, width=width, yerr=yerr, error_kw=error_kw, **hist_kwargs)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(feature_list,\n",
    "                       data_list,\n",
    "                       nbin=30,\n",
    "                       hist_kwargs_list={},\n",
    "                       error_kw_list={},\n",
    "                       ncols=2):\n",
    "    \"\"\"Plot feature distributions for several data set. Returns list of axes.\"\"\"\n",
    "    n_feature = len(feature_list)\n",
    "    nrows = int(n_feature / ncols) if n_feature % ncols == 0 else round((n_feature + 1) / ncols)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(5 * ncols,5 * nrows))\n",
    "    if nrows == 1 and ncols == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    for i, colname in enumerate(feature_list):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Range for binning\n",
    "        #range_min = min([data[colname].min() for data in data_list])\n",
    "        #range_max = max([data[colname].max() for data in data_list])\n",
    "        #myrange = [range_min, range_max]\n",
    "\n",
    "        for j, data in enumerate(data_list):\n",
    "            if colname in [\"hillas_intensity\", \"h_max\", \"impact_dist\"]: # automatically log these quantities for clarity\n",
    "                # Range for binning\n",
    "                range_min = min([np.log10(data[colname]).min() for data in data_list])\n",
    "                range_max = max([np.log10(data[colname]).max() for data in data_list])\n",
    "                myrange = [range_min, range_max]\n",
    "        \n",
    "                ax = plot_hist(\n",
    "                    ax=ax, data=np.log10(data[colname]), nbin=nbin, limit=myrange,\n",
    "                    norm=True, yerr=True,\n",
    "                    hist_kwargs=hist_kwargs_list[j],\n",
    "                    error_kw=error_kw_list[j]\n",
    "                )\n",
    "                ax.set_xlabel(f\"log10({colname})\")\n",
    "            else:\n",
    "                range_min = min([data[colname].min() for data in data_list])\n",
    "                range_max = max([data[colname].max() for data in data_list])\n",
    "                myrange = [range_min, range_max]\n",
    "                \n",
    "                ax = plot_hist(\n",
    "                    ax=ax, data=data[colname], nbin=nbin, limit=myrange,\n",
    "                    norm=True, yerr=True,\n",
    "                    hist_kwargs=hist_kwargs_list[j],\n",
    "                    error_kw=error_kw_list[j]\n",
    "                )\n",
    "\n",
    "                ax.set_xlabel(colname)\n",
    "\n",
    "        ax.set_ylabel('Arbitrary units')\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(ax, model_output, y, **kwargs):\n",
    "    \"\"\"Plot ROC curve for a given set of model outputs and labels\"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_score=model_output, y_true=y)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    label = '{} (area={:.2f})'.format(kwargs.pop('label'), roc_auc)  # Remove label\n",
    "    ax.plot(fpr, tpr, label=label, **kwargs)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evt_subarray_model_output(data,\n",
    "                                  weight_name=None,\n",
    "                                  keep_cols=['reco_energy'],\n",
    "                                  model_output_name='score_img',\n",
    "                                  model_output_name_evt='score'):\n",
    "    \"\"\"\n",
    "    Returns DataStore with keepcols + score/target columns of model at the\n",
    "    level-subarray-event.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: `~pandas.DataFrame`\n",
    "        Data frame\n",
    "    weight_name: `str`\n",
    "        Variable name in data frame to weight events with\n",
    "    keep_cols: `list`, optional\n",
    "        List of variables to keep in resulting data frame\n",
    "    model_output_name: `str`, optional\n",
    "        Name of model output (image level)\n",
    "    model_output_name_evt: `str`, optional\n",
    "        Name of averaged model output (event level)\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    data: `~pandas.DataFrame`\n",
    "        Data frame\n",
    "    \"\"\"\n",
    "\n",
    "    keep_cols += [model_output_name]\n",
    "    keep_cols += [weight_name]\n",
    "    new_data = data[keep_cols].copy(deep=True)\n",
    "\n",
    "    new_data[model_output_name_evt] = np.zeros(len(new_data))\n",
    "    new_data.set_index([\"tel_id\"], append=True, inplace=True)\n",
    "\n",
    "    new_data[model_output_name_evt] = new_data.groupby([\"obs_id\", \"event_id\"]).apply(\n",
    "        lambda g: np.average(g[model_output_name], weights=g[weight_name])\n",
    "    )\n",
    "\n",
    "    # Remove columns\n",
    "    new_data = new_data.drop(columns=[model_output_name])\n",
    "\n",
    "    # Remove duplicates\n",
    "    new_data = new_data[~new_data.index.duplicated(keep=\"first\")]\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelDiagnostic(object):\n",
    "    \"\"\"\n",
    "    Base class for model diagnostics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: `~sklearn.base.BaseEstimator`\n",
    "        Best model\n",
    "    feature_name_list: list\n",
    "        List of the features used to buil the model\n",
    "    target_name: str\n",
    "        Name of the target (e.g. score, gamaness, energy, etc.)\n",
    "    \"\"\"\n",
    "    def __init__(self, model, feature_name_list, target_name):\n",
    "        self.model = model\n",
    "        self.feature_name_list = feature_name_list\n",
    "        self.target_name = target_name\n",
    "\n",
    "    def plot_feature_importance(self, ax, **kwargs):\n",
    "        \"\"\"\n",
    "        Plot importance of features\n",
    "        Parameters\n",
    "        ----------\n",
    "        ax: `~matplotlib.axes.Axes`\n",
    "            Axis\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            import matplotlib.pyplot as plt\n",
    "            ax = plt.gca()\n",
    "\n",
    "        importance = self.model.feature_importances_\n",
    "        importance, feature_labels = \\\n",
    "            zip(*sorted(zip(importance, self.feature_name_list), reverse=True))\n",
    "\n",
    "        bin_edges = np.arange(0, len(importance)+1)\n",
    "        bin_width = bin_edges[1:] - bin_edges[:-1] - 0.1\n",
    "\n",
    "        ax.bar(bin_edges[:-1], importance, width=bin_width, **kwargs)\n",
    "        ax.set_xticks(np.arange(0, len(importance)))\n",
    "        ax.set_xticklabels(feature_labels, rotation=75)\n",
    "\n",
    "        return ax\n",
    "\n",
    "    def plot_features(self, data_list,\n",
    "                      nbin=30,\n",
    "                      hist_kwargs_list={},\n",
    "                      error_kw_list={},\n",
    "                      ncols=2):\n",
    "        \"\"\"\n",
    "        Plot model features for different data set (e.g. training and test samples).\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_list: list\n",
    "            List of data\n",
    "        nbin: int\n",
    "            Number of bin\n",
    "        hist_kwargs_list: dict\n",
    "            Dictionary with histogram options\n",
    "        error_kw_list: dict\n",
    "            Dictionary with error bar options\n",
    "        ncols: int\n",
    "            Number of columns\n",
    "        \"\"\"\n",
    "        return plot_distributions(\n",
    "            self.feature_name_list,\n",
    "            data_list,\n",
    "            nbin,\n",
    "            hist_kwargs_list,\n",
    "            error_kw_list, ncols\n",
    "        )\n",
    "\n",
    "    def add_image_model_output(self):\n",
    "        raise NotImplementedError(\"Please Implement this method\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierDiagnostic(ModelDiagnostic):\n",
    "    \"\"\"\n",
    "    Class to plot several diagnostic plot for classification. Assume that positives and\n",
    "    negatives are respectively labeled as 1 and 0.\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: sklearn.base.BaseEstimator\n",
    "        Scikit model\n",
    "    feature_name_list: list\n",
    "        List of features\n",
    "    model_output_name: str\n",
    "        Name of output\n",
    "    is_output_proba: bool\n",
    "        If false, `decision_function` will be called, otherwise, predict_proba.\n",
    "        In the last case we only consider the probability for signal event\n",
    "    \"\"\"\n",
    "    def __init__(self, model, feature_name_list, target_name,\n",
    "                 data_train, data_test, model_output_name='score', is_output_proba=False):\n",
    "        super().__init__(model, feature_name_list, target_name)\n",
    "\n",
    "        self.data_train = data_train\n",
    "        self.data_test = data_test\n",
    "        self.model_output_name = model_output_name\n",
    "        self.is_output_proba = is_output_proba\n",
    "\n",
    "        # Compute and add model output\n",
    "        self.data_train = self.add_image_model_output(\n",
    "            self.data_train,\n",
    "            col_name=self.model_output_name\n",
    "        )\n",
    "        self.data_test = self.add_image_model_output(\n",
    "            self.data_test,\n",
    "            col_name=self.model_output_name\n",
    "        )\n",
    "\n",
    "    def add_image_model_output(self, data, col_name):\n",
    "        \"\"\"Add model output column\"\"\"\n",
    "        if self.is_output_proba is False:\n",
    "            data[col_name] = self.model.decision_function(data[self.feature_name_list])\n",
    "        else:  # Interested in signal probability\n",
    "            data[col_name] = self.model.predict_proba(data[self.feature_name_list].to_numpy())[:,1]\n",
    "        return data\n",
    "\n",
    "    def plot_image_model_output_distribution(\n",
    "            self,\n",
    "            cut=None,\n",
    "            nbin=30,\n",
    "            hist_kwargs_list=[\n",
    "                {'edgecolor': 'blue', 'color': 'blue', 'label': 'Gamma training sample',\n",
    "                'alpha': 0.2, 'fill': True, 'ls': '-', 'lw': 2},\n",
    "                {'edgecolor': 'blue', 'color': 'blue', 'label': 'Gamma test sample',\n",
    "                'alpha': 1, 'fill': False, 'ls': '--', 'lw': 2},\n",
    "                {'edgecolor': 'red', 'color': 'red', 'label': 'Proton training sample',\n",
    "                'alpha': 0.2, 'fill': True, 'ls': '-', 'lw': 2},\n",
    "                {'edgecolor': 'red', 'color': 'red', 'label': 'Proton test sample',\n",
    "                'alpha': 1, 'fill': False, 'ls': '--', 'lw': 2}\n",
    "            ],\n",
    "            error_kw_list=[\n",
    "                dict(ecolor='blue', lw=2, capsize=3, capthick=2, alpha=0.2),\n",
    "                dict(ecolor='blue', lw=2, capsize=3, capthick=2, alpha=1),\n",
    "                dict(ecolor='red', lw=2, capsize=3, capthick=2, alpha=0.2),\n",
    "                dict(ecolor='red', lw=2, capsize=3, capthick=2, alpha=1)\n",
    "                ]\n",
    "    ):\n",
    "        \"\"\"Plot output distribution. Need more output column\"\"\"\n",
    "        if cut is not None:\n",
    "            data_test = self.data_test.query(cut)\n",
    "            data_train = self.data_train.query(cut)\n",
    "        else:\n",
    "            data_test = self.data_test\n",
    "            data_train = self.data_train\n",
    "\n",
    "        return plot_distributions(\n",
    "            [self.model_output_name],\n",
    "            [data_train.query('label==1'), data_test.query('label==1'),\n",
    "             data_train.query('label==0'), data_test.query('label==0')],\n",
    "            nbin,\n",
    "            hist_kwargs_list,\n",
    "            error_kw_list,\n",
    "            1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoostedDecisionTreeDiagnostic(object):\n",
    "    \"\"\"\n",
    "    Class producing diagnostic plot for the BDT method\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def plot_error_rate(cls, ax, model, data_scikit, **kwargs):\n",
    "        \"\"\"Diagnostic plot showing error rate as a function of the specialisation\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        if ax is None:\n",
    "            ax = plt.gca()\n",
    "\n",
    "        test_errors = []\n",
    "        for test_predict in model.staged_predict(data_scikit[\"X_test\"]):\n",
    "            test_errors.append(\n",
    "                1.0 - accuracy_score(test_predict, data_scikit[\"y_test\"])\n",
    "            )\n",
    "\n",
    "        ntrees = len(model)\n",
    "        ax.plot(range(1, ntrees + 1), test_errors, **kwargs)\n",
    "        ax.set_xlabel(\"Number of Trees\")\n",
    "        ax.set_ylabel(\"Error rate\")\n",
    "        ax.grid()\n",
    "        plt.tight_layout()\n",
    "        return ax\n",
    "\n",
    "    @classmethod\n",
    "    def plot_tree_error_rate(cls, ax, model, **kwargs):\n",
    "        \"\"\"Diagnostic plot showing tree error rate\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        if ax is None:\n",
    "            ax = plt.gca()\n",
    "\n",
    "        ntrees = len(model)\n",
    "        estimator_errors = model.estimator_errors_[:ntrees]\n",
    "\n",
    "        ntrees = len(model)\n",
    "        ax.plot(range(1, ntrees + 1), estimator_errors, **kwargs)\n",
    "        ax.set_xlabel(\"Tree number\")\n",
    "        ax.set_ylabel(\"Error rate / tree\")\n",
    "        ax.grid()\n",
    "        plt.tight_layout()\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "hide_cell",
     "remove_input"
    ]
   },
   "source": [
    "## Load models\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "analyses_directory = None\n",
    "analysis_name = None\n",
    "analysis_name_2 = None\n",
    "model_configuration_filename = None # Name of the configuration file of the model\n",
    "output_directory = Path.cwd() # default output directory for plots\n",
    "use_seaborn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle boolean variables (papermill reads them as strings)\n",
    "use_seaborn = string_to_boolean([use_seaborn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the model configuration file has been defined\n",
    "# either from the CLI of from the benchmarks configuration file (default)\n",
    "if model_configuration_filename is None:\n",
    "    try:\n",
    "        model_configuration_filename = model_configuration_filenames[\"classification\"]\n",
    "    except KeyError:\n",
    "        raise ValueError(\"The name of the configuration file is undefined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_configuration_path = Path(analyses_directory) / analysis_name / Path(\"configs/analysis.yaml\")\n",
    "model_configuration_path = Path(analyses_directory) / analysis_name / \"configs\" / model_configuration_filename\n",
    "input_directory = Path(analyses_directory) / analysis_name / Path(\"estimators/gamma_hadron_classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration files\n",
    "ana_cfg = load_config(analysis_configuration_path)\n",
    "cfg = load_config(model_configuration_path)\n",
    "\n",
    "# Get info from configs\n",
    "model_type = \"classifier\"\n",
    "method_name = cfg[\"Method\"][\"name\"].split(\".\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = [model.split('/')[-1].split('_')[1] for model in glob.glob(f\"{input_directory}/{model_type}*.pkl.gz\")]\n",
    "data = {camera : dict.fromkeys([\"model\", \"data_scikit\", \"data_train\", \"data_test\"]) for camera in cameras} \n",
    "\n",
    "for camera in cameras:\n",
    "\n",
    "    data[camera][\"data_scikit\"] = load_obj(\n",
    "                glob.glob(f\"{input_directory}/data_scikit_{model_type}_{method_name}_{camera}.pkl.gz\")[0]\n",
    "                )\n",
    "    data[camera][\"data_train\"] = pd.read_pickle(\n",
    "        glob.glob(f\"{input_directory}/data_train_{model_type}_{method_name}_{camera}.pkl.gz\")[0]\n",
    "                )\n",
    "    data[camera][\"data_test\"] = pd.read_pickle(\n",
    "        glob.glob(f\"{input_directory}/data_test_{model_type}_{method_name}_{camera}.pkl.gz\")[0]\n",
    "    )\n",
    "    \n",
    "    modelName = f\"{model_type}_{camera}_{method_name}.pkl.gz\"\n",
    "    data[camera][\"model\"] = joblib.load(glob.glob(f\"{input_directory}/{model_type}_{camera}_{method_name}.pkl.gz\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "hide_cell",
     "remove_input"
    ]
   },
   "source": [
    "## Settings and setup\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if cfg[\"Method\"][\"use_proba\"] is True:\n",
    "        output_model_name = \"gammaness\"\n",
    "    else:\n",
    "        output_model_name = \"score\"\n",
    "except KeyError:\n",
    "    output_model_name = \"gammaness\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy (both true and reconstructed) [TeV]\n",
    "nbins = cfg[\"Diagnostic\"][\"energy\"][\"nbins\"]\n",
    "\n",
    "energy_edges = np.logspace(\n",
    "        np.log10(cfg[\"Diagnostic\"][\"energy\"][\"min\"]),\n",
    "        np.log10(cfg[\"Diagnostic\"][\"energy\"][\"max\"]),\n",
    "        nbins + 1,\n",
    "        True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for energy variation\n",
    "cut_list = [\n",
    "    \"reco_energy >= {:.2f} and reco_energy <= {:.2f}\".format(\n",
    "        energy_edges[i], energy_edges[i + 1]\n",
    "    )\n",
    "    for i in range(len(energy_edges) - 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_basic = cfg[\"FeatureList\"][\"Basic\"]\n",
    "features_derived = cfg[\"FeatureList\"][\"Derived\"]\n",
    "features = features_basic + list(features_derived)\n",
    "features = sorted(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic = dict.fromkeys(cameras)\n",
    "for camera in cameras:   \n",
    "    diagnostic[camera] = ClassifierDiagnostic(\n",
    "                            model=data[camera][\"model\"],\n",
    "                            feature_name_list=features,\n",
    "                            target_name=cfg[\"Method\"][\"target_name\"],\n",
    "                            data_train=data[camera][\"data_train\"],\n",
    "                            data_test=data[camera][\"data_test\"],\n",
    "                            model_output_name=output_model_name,\n",
    "                            is_output_proba=cfg[\"Method\"][\"use_proba\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden",
    "tags": [
     "hide_cell"
    ]
   },
   "source": [
    "## Benchmarks\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we check if a _plots_ folder exists already.  \n",
    "# If not, we create it.\n",
    "plots_folder = Path(output_directory) / \"plots\"\n",
    "plots_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot aesthetics settings\n",
    "\n",
    "style.use(matplotlib_settings[\"style\"])\n",
    "cmap = matplotlib_settings[\"cmap\"]\n",
    "\n",
    "if matplotlib_settings[\"style\"] == \"seaborn-colorblind\":\n",
    "    \n",
    "    colors_order = ['#0072B2', '#D55E00', '#F0E442', '#009E73', '#CC79A7', '#56B4E9']\n",
    "    rc('axes', prop_cycle=cycler(color=colors_order))\n",
    "\n",
    "if use_seaborn:\n",
    "    import seaborn as sns\n",
    "\n",
    "    sns.set_theme(context=seaborn_settings[\"theme\"][\"context\"] if \"context\" in seaborn_settings[\"theme\"] else \"talk\",\n",
    "                  style=seaborn_settings[\"theme\"][\"style\"] if \"style\" in seaborn_settings[\"theme\"] else \"whitegrid\",\n",
    "                  palette=seaborn_settings[\"theme\"][\"palette\"] if \"palette\" in seaborn_settings[\"theme\"] else None,\n",
    "                  font=seaborn_settings[\"theme\"][\"font\"] if \"font\" in seaborn_settings[\"theme\"] else \"Fira Sans\",\n",
    "                  font_scale=seaborn_settings[\"theme\"][\"font_scale\"] if \"font_scale\" in seaborn_settings[\"theme\"] else 1.0,\n",
    "                  color_codes=seaborn_settings[\"theme\"][\"color_codes\"] if \"color_codes\" in seaborn_settings[\"theme\"] else True\n",
    "                  )\n",
    "    \n",
    "    sns.set_style(seaborn_settings[\"theme\"][\"style\"], rc=seaborn_settings[\"rc_style\"])\n",
    "    sns.set_context(seaborn_settings[\"theme\"][\"context\"],\n",
    "                    font_scale=seaborn_settings[\"theme\"][\"font_scale\"] if \"font_scale\" in seaborn_settings[\"theme\"] else 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for camera in cameras:\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    ax = plt.gca()\n",
    "    ax = diagnostic[camera].plot_feature_importance(\n",
    "        ax,\n",
    "        **{\"alpha\": 0.7, \"edgecolor\": \"black\", \"linewidth\": 2, \"color\": \"darkgreen\"}\n",
    "    )\n",
    "    ax.set_ylabel(\"Feature importance\")\n",
    "    ax.grid()\n",
    "    plt.title(camera)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature distributions\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** quantities like ``h_max`` and ``impact_dist`` are automatically shown as ``log10`` for these plots for better clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for camera in cameras:\n",
    "    \n",
    "    fig, axes = diagnostic[camera].plot_features(\n",
    "                data_list=[\n",
    "                    data[camera][\"data_train\"].query(\"label==1\"),\n",
    "                    data[camera][\"data_test\"].query(\"label==1\"),\n",
    "                    data[camera][\"data_train\"].query(\"label==0\"),\n",
    "                    data[camera][\"data_test\"].query(\"label==0\"),\n",
    "                ],\n",
    "                nbin=30,\n",
    "                hist_kwargs_list=[\n",
    "                    {\n",
    "                        \"edgecolor\": \"blue\",\n",
    "                        \"color\": \"blue\",\n",
    "                        \"label\": \"Gamma training sample\",\n",
    "                        \"alpha\": 0.2,\n",
    "                        \"fill\": True,\n",
    "                        \"ls\": \"-\",\n",
    "                        \"lw\": 2,\n",
    "                    },\n",
    "                    {\n",
    "                        \"edgecolor\": \"blue\",\n",
    "                        \"color\": \"blue\",\n",
    "                        \"label\": \"Gamma test sample\",\n",
    "                        \"alpha\": 1,\n",
    "                        \"fill\": False,\n",
    "                        \"ls\": \"--\",\n",
    "                        \"lw\": 2,\n",
    "                    },\n",
    "                    {\n",
    "                        \"edgecolor\": \"red\",\n",
    "                        \"color\": \"red\",\n",
    "                        \"label\": \"Proton training sample\",\n",
    "                        \"alpha\": 0.2,\n",
    "                        \"fill\": True,\n",
    "                        \"ls\": \"-\",\n",
    "                        \"lw\": 2,\n",
    "                    },\n",
    "                    {\n",
    "                        \"edgecolor\": \"red\",\n",
    "                        \"color\": \"red\",\n",
    "                        \"label\": \"Proton test sample\",\n",
    "                        \"alpha\": 1,\n",
    "                        \"fill\": False,\n",
    "                        \"ls\": \"--\",\n",
    "                        \"lw\": 2,\n",
    "                    },\n",
    "                ],\n",
    "                error_kw_list=[\n",
    "                    dict(ecolor=\"blue\", lw=2, capsize=3, capthick=2, alpha=0.2),\n",
    "                    dict(ecolor=\"blue\", lw=2, capsize=3, capthick=2, alpha=1),\n",
    "                    dict(ecolor=\"red\", lw=2, capsize=3, capthick=2, alpha=0.2),\n",
    "                    dict(ecolor=\"red\", lw=2, capsize=3, capthick=2, alpha=1),\n",
    "                ],\n",
    "                ncols=3,\n",
    "            )\n",
    "    plt.suptitle(camera)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosted Decision Tree Error rate\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if method_name != \"AdaBoostClassifier\":\n",
    "    \n",
    "    print(\"The model is not an AdaBoostClassifier\")\n",
    "\n",
    "else:\n",
    "    \n",
    "    for camera in cameras:\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        ax = plt.gca()\n",
    "        opt = {\"color\": \"darkgreen\", \"ls\": \"-\", \"lw\": 2}\n",
    "        BoostedDecisionTreeDiagnostic.plot_error_rate(\n",
    "            ax, model, data_scikit, **opt\n",
    "        )\n",
    "        plt.title(camera)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        ax = plt.gca()\n",
    "        BoostedDecisionTreeDiagnostic.plot_tree_error_rate(ax, model, **opt)\n",
    "        plt.title(camera)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model output\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for camera in cameras:\n",
    "\n",
    "    fig, ax = diagnostic[camera].plot_image_model_output_distribution(nbin=50)\n",
    "    ax[0].set_xlim([0, 1])\n",
    "    ax[0].set_ylim([0, 1])\n",
    "    plt.title(camera)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    ax = plt.gca()\n",
    "    plot_roc_curve(\n",
    "        ax,\n",
    "        diagnostic[camera].data_train[diagnostic[camera].model_output_name],\n",
    "        diagnostic[camera].data_train[cfg[\"Method\"][\"target_name\"]],\n",
    "        **dict(color=\"darkgreen\", lw=2, label=\"Training sample\")\n",
    "    )\n",
    "    plot_roc_curve(\n",
    "        ax,\n",
    "        data[camera][\"data_test\"][diagnostic[camera].model_output_name],\n",
    "        diagnostic[camera].data_test[cfg[\"Method\"][\"target_name\"]],\n",
    "        **dict(color=\"darkorange\", lw=2, label=\"Test sample\")\n",
    "    )\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.title(camera)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy-dependent distributions\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_kwargs_list = [\n",
    "    {\n",
    "        \"edgecolor\": \"blue\",\n",
    "        \"color\": \"blue\",\n",
    "        \"label\": \"Gamma training sample\",\n",
    "        \"alpha\": 0.2,\n",
    "        \"fill\": True,\n",
    "        \"ls\": \"-\",\n",
    "        \"lw\": 2,\n",
    "    },\n",
    "    {\n",
    "        \"edgecolor\": \"blue\",\n",
    "        \"color\": \"blue\",\n",
    "        \"label\": \"Gamma test sample\",\n",
    "        \"alpha\": 1,\n",
    "        \"fill\": False,\n",
    "        \"ls\": \"--\",\n",
    "        \"lw\": 2,\n",
    "    },\n",
    "    {\n",
    "        \"edgecolor\": \"red\",\n",
    "        \"color\": \"red\",\n",
    "        \"label\": \"Proton training sample\",\n",
    "        \"alpha\": 0.2,\n",
    "        \"fill\": True,\n",
    "        \"ls\": \"-\",\n",
    "        \"lw\": 2,\n",
    "    },\n",
    "    {\n",
    "        \"edgecolor\": \"red\",\n",
    "        \"color\": \"red\",\n",
    "        \"label\": \"Proton test sample\",\n",
    "        \"alpha\": 1,\n",
    "        \"fill\": False,\n",
    "        \"ls\": \"--\",\n",
    "        \"lw\": 2,\n",
    "    },\n",
    "]\n",
    "\n",
    "error_kw_list = [\n",
    "    dict(ecolor=\"blue\", lw=2, capsize=3, capthick=2, alpha=0.2),\n",
    "    dict(ecolor=\"blue\", lw=2, capsize=3, capthick=2, alpha=1),\n",
    "    dict(ecolor=\"red\", lw=2, capsize=3, capthick=2, alpha=0.2),\n",
    "    dict(ecolor=\"red\", lw=2, capsize=3, capthick=2, alpha=1),\n",
    "]\n",
    "\n",
    "n_feature = len(cut_list)\n",
    "ncols = 2\n",
    "nrows = (\n",
    "    int(n_feature / ncols)\n",
    "    if n_feature % ncols == 0\n",
    "    else int((n_feature + 1) / ncols)\n",
    ")\n",
    "\n",
    "for camera in cameras:\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nrows, ncols=ncols, figsize=(5 * ncols, 5 * nrows)\n",
    "    )\n",
    "    plt.subplots_adjust(hspace=0.5, wspace=0.5)\n",
    "    if nrows == 1 and ncols == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    data_list = [\n",
    "        data[camera][\"data_train\"].query(\"label==1\"),\n",
    "        data[camera][\"data_test\"].query(\"label==1\"),\n",
    "        data[camera][\"data_train\"].query(\"label==0\"),\n",
    "        data[camera][\"data_test\"].query(\"label==0\"),\n",
    "    ]\n",
    "\n",
    "    for i, colname in enumerate(cut_list):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # Range for binning\n",
    "        the_range = [0, 1]\n",
    "\n",
    "        for j, d in enumerate(data_list):\n",
    "            if len(d) == 0:\n",
    "                continue\n",
    "\n",
    "            ax = plot_hist(\n",
    "                ax=ax,\n",
    "                data=d.query(cut_list[i])[output_model_name],\n",
    "                nbin=30,\n",
    "                limit=the_range,\n",
    "                norm=True,\n",
    "                yerr=True,\n",
    "                hist_kwargs=hist_kwargs_list[j],\n",
    "                error_kw=error_kw_list[j],\n",
    "            )\n",
    "\n",
    "        ax.set_xlim(the_range)\n",
    "        ax.set_ylim(0,1.2)\n",
    "        ax.set_xlabel(output_model_name)\n",
    "        ax.set_ylabel(\"Arbitrary units\")\n",
    "        #ax.legend(loc=\"best\", fontsize=\"small\")\n",
    "        ax.legend(loc=\"upper center\")\n",
    "        ax.set_title(f\"{energy_edges[i]:.2f} TeV < E_reco < {energy_edges[i+1]:.2f} TeV\")\n",
    "        ax.grid()\n",
    "\n",
    "    plt.suptitle(camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curve variation on test sample\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for camera in cameras:\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    color = 1.0\n",
    "    step_color = 1.0 / (len(cut_list))\n",
    "    for i, cut in enumerate(cut_list):\n",
    "        c = color - (i + 1) * step_color\n",
    "\n",
    "        test_data = data[camera][\"data_test\"].query(cut)\n",
    "        if len(test_data) == 0:\n",
    "            continue\n",
    "\n",
    "        opt = dict(\n",
    "            color=str(c),\n",
    "            lw=2,\n",
    "            #label=\"{}\".format(cut.replace(\"reco_energy\", \"E\")),\n",
    "            label=f\"{energy_edges[i]:.2f} TeV < E_reco < {energy_edges[i+1]:.2f} TeV\"\n",
    "        )\n",
    "        plot_roc_curve(ax, test_data[output_model_name], test_data[cfg[\"Method\"][\"target_name\"]], **opt)\n",
    "    ax.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "    ax.set_title(camera)\n",
    "    ax.set_xlabel(\"False Positive Rate\")\n",
    "    ax.set_ylabel(\"True Positive Rate\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC as a function of reconstructed energy\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finer_energy_edges = np.logspace(\n",
    "        np.log10(0.02),\n",
    "        np.log10(200),\n",
    "        21,\n",
    "        True,\n",
    "    )\n",
    "\n",
    "cut_list_with_finer_energy_edges = [\n",
    "    \"reco_energy >= {:.2f} and reco_energy <= {:.2f}\".format(\n",
    "        finer_energy_edges[i], finer_energy_edges[i + 1]\n",
    "    )\n",
    "    for i in range(len(finer_energy_edges) - 1)\n",
    "]\n",
    "\n",
    "for camera in cameras:\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.title(camera)\n",
    "    \n",
    "    aucs = []\n",
    "    reco_energy = []\n",
    "    \n",
    "    for i, cut in enumerate(cut_list_with_finer_energy_edges):\n",
    "    \n",
    "        selected_images = data[camera][\"data_test\"].query(cut)\n",
    "        if len(selected_images)==0:\n",
    "            continue\n",
    "    \n",
    "        fpr, tpr, _ = roc_curve(y_score=selected_images[output_model_name], y_true=selected_images[cfg[\"Method\"][\"target_name\"]])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        aucs.append(roc_auc)\n",
    "        reco_energy.append( 0.5 * (finer_energy_edges[i] + finer_energy_edges[i+1]) )\n",
    "\n",
    "    plt.plot(reco_energy, aucs, \"bo\")\n",
    "    plt.hlines(1, xmin=plt.gca().get_xlim()[0], xmax=plt.gca().get_xlim()[1], linestyles=\"dashed\", color=\"green\")\n",
    "    plt.ylim(0,1.2)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"log10(Reconstructed energy [TeV])\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-Recall\n",
    "[back to top](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "try:\n",
    "    if cfg[\"Method\"][\"use_proba\"] is True:\n",
    "        response_method = \"predict_proba\"\n",
    "    else:\n",
    "        response_method = \"decision_function\"\n",
    "except KeyError:\n",
    "    response_method = \"predict_proba\"\n",
    "\n",
    "for camera in cameras:\n",
    "    \n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.grid()\n",
    "    plt.title(camera)\n",
    "    \n",
    "    for i, cut in enumerate(cut_list):\n",
    "        c = color - (i + 1) * step_color\n",
    "\n",
    "        selected_test_data = diagnostic[camera].data_test.query(cut)\n",
    "\n",
    "        if len(test_data) == 0:\n",
    "            continue\n",
    "\n",
    "        opt = dict(\n",
    "            color=str(c),\n",
    "            lw=2,\n",
    "            label=f\"{energy_edges[i]:.2f} TeV < E_reco < {energy_edges[i+1]:.2f} TeV\"\n",
    "        )\n",
    "\n",
    "        PrecisionRecallDisplay.from_estimator(diagnostic[camera].model, \n",
    "                                    selected_test_data[features].to_numpy(),\n",
    "                                    selected_test_data[cfg[\"Method\"][\"target_name\"]],\n",
    "                                    response_method=response_method,\n",
    "                                    ax=plt.gca(),\n",
    "                                    name=opt[\"label\"])\n",
    "        \n",
    "\n",
    "    plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
